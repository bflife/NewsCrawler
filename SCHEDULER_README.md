# æ–°é—»çˆ¬è™«è°ƒåº¦ç³»ç»Ÿ

## æ¦‚è¿°

æœ¬ç³»ç»Ÿæ‰©å±•äº†åŸæœ‰çš„NewsCrawleré¡¹ç›®ï¼Œå¢åŠ äº†ä»¥ä¸‹æ ¸å¿ƒåŠŸèƒ½ï¼š

1. **å›½å®¶/åœ°åŒºåˆ†ç±»ç³»ç»Ÿ** - æ”¯æŒæŒ‰å›½å®¶å’Œåœ°åŒºåˆ†ç±»ç®¡ç†æ–°é—»æº
2. **å®šæ—¶è°ƒåº¦ç³»ç»Ÿ** - æ”¯æŒç”¨æˆ·è‡ªå®šä¹‰æ—¶é—´é—´éš”çš„å®šæ—¶çˆ¬å–
3. **é€šç”¨çˆ¬è™«æ¡†æ¶** - æä¾›å¯æ‰©å±•çš„é€šç”¨çˆ¬è™«åŸºç±»
4. **æ•°æ®åº“ç®¡ç†** - SQLiteæ•°æ®åº“å­˜å‚¨çˆ¬å–å†å²å’Œä»»åŠ¡é…ç½®
5. **å¤šæ–°é—»æºæ”¯æŒ** - å·²é›†æˆ200+å…¨çƒæ–°é—»ç½‘ç«™

## æ”¯æŒçš„å›½å®¶/åœ°åŒº

ç›®å‰æ”¯æŒä»¥ä¸‹å›½å®¶å’Œåœ°åŒºçš„æ–°é—»æºï¼š

- ğŸ‡¨ğŸ‡³ **ä¸­å›½å¤§é™†** - å›½å†…ä¸»æµæ–°é—»ç½‘ç«™
- ğŸ‡­ğŸ‡° **é¦™æ¸¯** - å¤§å…¬æŠ¥ã€è‹¹æœæ—¥æŠ¥ã€é¦™æ¸¯01ç­‰20+ç½‘ç«™
- ğŸ‡¹ğŸ‡¼ **å°æ¹¾** - è‡ªç”±æ—¶æŠ¥ã€è”åˆæŠ¥ã€ä¸­æ—¶ç”µå­æŠ¥ç­‰17+ç½‘ç«™
- ğŸ‡¸ğŸ‡¬ **æ–°åŠ å¡** - è”åˆæ—©æŠ¥
- ğŸ‡²ğŸ‡¾ **é©¬æ¥è¥¿äºš** - æ˜Ÿæ´²æ—¥æŠ¥ã€å—æ´‹å•†æŠ¥ç­‰10+ç½‘ç«™
- ğŸ‡¯ğŸ‡µ **æ—¥æœ¬** - NHKã€æœæ—¥æ–°é—»ã€è¯»å–æ–°é—»ç­‰18+ç½‘ç«™
- ğŸ‡°ğŸ‡· **éŸ©å›½** - éŸ©è”ç¤¾ã€æœé²œæ—¥æŠ¥ç­‰
- ğŸ‡ºğŸ‡¸ **ç¾å›½** - CNNã€çº½çº¦æ—¶æŠ¥ã€åå°”è¡—æ—¥æŠ¥ç­‰40+ç½‘ç«™
- ğŸ‡¬ğŸ‡§ **è‹±å›½** - BBCã€è·¯é€ç¤¾ã€é‡‘èæ—¶æŠ¥ç­‰8+ç½‘ç«™
- ğŸ‡«ğŸ‡· **æ³•å›½** - æ³•æ–°ç¤¾ã€ä¸–ç•ŒæŠ¥ç­‰5+ç½‘ç«™
- ğŸ‡·ğŸ‡º **ä¿„ç½—æ–¯** - ä¿„ç½—æ–¯å«æ˜Ÿé€šè®¯ç¤¾ç­‰4+ç½‘ç«™
- ğŸ‡¦ğŸ‡º **æ¾³å¤§åˆ©äºš** - æ¾³å¤§åˆ©äºšå¹¿æ’­å…¬å¸ã€æ¯æ—¥ç”µè®¯æŠ¥ç­‰
- ğŸ‡²ğŸ‡´ **æ¾³é—¨** - æ¾³é—¨æ—¥æŠ¥ã€åŠ›æŠ¥ç­‰10+ç½‘ç«™
- ğŸ‡»ğŸ‡³ **è¶Šå—** - è¶Šå—é€šè®¯ç¤¾ç­‰
- ğŸ‡®ğŸ‡³ **å°åº¦** - å°åº¦æ–¯å¦æ—¶æŠ¥ç­‰
- ä»¥åŠå…¶ä»–å›½å®¶å’Œåœ°åŒº...

## é¡¹ç›®ç»“æ„

```
news_crawler/
â”œâ”€â”€ config/
â”‚   â””â”€â”€ news_sources.json      # æ–°é—»æºé…ç½®æ–‡ä»¶ï¼ˆ200+ç½‘ç«™ï¼‰
â”œâ”€â”€ scheduler/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ models.py               # æ•°æ®æ¨¡å‹ï¼ˆä»»åŠ¡ã€å†å²ã€æ–‡ç« ï¼‰
â”‚   â”œâ”€â”€ database.py             # SQLiteæ•°æ®åº“ç®¡ç†
â”‚   â””â”€â”€ scheduler.py            # è°ƒåº¦å™¨æ ¸å¿ƒ
â”œâ”€â”€ generic/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ crawler.py              # é€šç”¨çˆ¬è™«åŸºç±»
â”œâ”€â”€ sites/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ crawlers.py             # å…·ä½“ç½‘ç«™çˆ¬è™«å®ç°
â””â”€â”€ ...

scheduler_cli.py                # å‘½ä»¤è¡Œç®¡ç†å·¥å…·
data/
â””â”€â”€ news_crawler.db             # SQLiteæ•°æ®åº“æ–‡ä»¶
```

## å¿«é€Ÿå¼€å§‹

### 1. å®‰è£…ä¾èµ–

```bash
# ç¡®ä¿å·²å®‰è£…uv
uv sync
```

### 2. åˆå§‹åŒ–ä»»åŠ¡

ä»é…ç½®æ–‡ä»¶åŠ è½½æ‰€æœ‰æ–°é—»æºå¹¶åˆ›å»ºçˆ¬å–ä»»åŠ¡ï¼š

```bash
# åˆå§‹åŒ–ä»»åŠ¡ï¼Œé»˜è®¤60åˆ†é’Ÿé—´éš”
uv run python scheduler_cli.py init --interval 60

# æˆ–æŒ‡å®šå…¶ä»–é—´éš”ï¼ˆä¾‹å¦‚120åˆ†é’Ÿï¼‰
uv run python scheduler_cli.py init --interval 120
```

### 3. æŸ¥çœ‹ä»»åŠ¡

```bash
# åˆ—å‡ºæ‰€æœ‰ä»»åŠ¡
uv run python scheduler_cli.py list

# åˆ—å‡ºæŒ‡å®šå›½å®¶çš„ä»»åŠ¡
uv run python scheduler_cli.py list --country å°æ¹¾
uv run python scheduler_cli.py list --country é¦™æ¸¯
uv run python scheduler_cli.py list --country æ—¥æœ¬

# åˆ—å‡ºæ‰€æœ‰å›½å®¶
uv run python scheduler_cli.py countries
```

### 4. å¯åŠ¨è°ƒåº¦å™¨

```bash
# å¯åŠ¨åå°è°ƒåº¦å™¨ï¼ˆæ¯åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡ä»»åŠ¡ï¼‰
uv run python scheduler_cli.py start
```

è°ƒåº¦å™¨ä¼šï¼š
- æ¯60ç§’æ£€æŸ¥ä¸€æ¬¡æ‰€æœ‰ä»»åŠ¡
- å¯¹äºåˆ°æœŸçš„ä»»åŠ¡ï¼Œè‡ªåŠ¨æ‰§è¡Œçˆ¬å–
- å°†çˆ¬å–ç»“æœä¿å­˜åˆ°æ•°æ®åº“
- è®°å½•çˆ¬å–å†å²å’Œé”™è¯¯ä¿¡æ¯

### 5. æ‰‹åŠ¨æ‰§è¡Œä»»åŠ¡

```bash
# æ‰§è¡ŒæŒ‡å®šæ–°é—»æºçš„çˆ¬å–ä»»åŠ¡
uv run python scheduler_cli.py run --source-id zaobao

# æ‰§è¡Œæ‰€æœ‰åˆ°æœŸçš„ä»»åŠ¡
uv run python scheduler_cli.py run
```

### 6. æŸ¥çœ‹çˆ¬å–å†å²

```bash
# æŸ¥çœ‹æœ€è¿‘20æ¡çˆ¬å–å†å²
uv run python scheduler_cli.py history --limit 20

# æŸ¥çœ‹æŒ‡å®šæ–°é—»æºçš„å†å²
uv run python scheduler_cli.py history --source-id zaobao --limit 50
```

### 7. ç®¡ç†ä»»åŠ¡

```bash
# æŸ¥çœ‹ç»Ÿè®¡ä¿¡æ¯
uv run python scheduler_cli.py stats

# å¯ç”¨/ç¦ç”¨ä»»åŠ¡
uv run python scheduler_cli.py enable --source-id zaobao
uv run python scheduler_cli.py disable --source-id zaobao

# è®¾ç½®ä»»åŠ¡é—´éš”ï¼ˆåˆ†é’Ÿï¼‰
uv run python scheduler_cli.py set-interval --source-id zaobao --interval 120
```

## å‘½ä»¤è¡Œå·¥å…·è¯¦è§£

### init - åˆå§‹åŒ–ä»»åŠ¡

ä»é…ç½®æ–‡ä»¶åŠ è½½æ–°é—»æºå¹¶åˆ›å»ºçˆ¬å–ä»»åŠ¡ã€‚

```bash
uv run python scheduler_cli.py init [--interval MINUTES]
```

å‚æ•°ï¼š
- `--interval`: é»˜è®¤çˆ¬å–é—´éš”ï¼ˆåˆ†é’Ÿï¼‰ï¼Œé»˜è®¤60

### start - å¯åŠ¨è°ƒåº¦å™¨

å¯åŠ¨åå°è°ƒåº¦å™¨ï¼Œè‡ªåŠ¨æ‰§è¡Œå®šæ—¶ä»»åŠ¡ã€‚

```bash
uv run python scheduler_cli.py start
```

æŒ‰ `Ctrl+C` åœæ­¢è°ƒåº¦å™¨ã€‚

### run - æ‰‹åŠ¨æ‰§è¡Œä»»åŠ¡

æ‰‹åŠ¨è§¦å‘çˆ¬å–ä»»åŠ¡ã€‚

```bash
uv run python scheduler_cli.py run [--source-id SOURCE_ID]
```

å‚æ•°ï¼š
- `--source-id`: æŒ‡å®šæ–°é—»æºIDï¼Œä¸æŒ‡å®šåˆ™æ‰§è¡Œæ‰€æœ‰åˆ°æœŸä»»åŠ¡

### list - åˆ—å‡ºä»»åŠ¡

åˆ—å‡ºæ‰€æœ‰æˆ–æŒ‡å®šå›½å®¶çš„çˆ¬å–ä»»åŠ¡ã€‚

```bash
uv run python scheduler_cli.py list [--country COUNTRY]
```

å‚æ•°ï¼š
- `--country`: æŒ‰å›½å®¶/åœ°åŒºç­›é€‰ï¼Œä¾‹å¦‚ï¼š"å°æ¹¾"ã€"é¦™æ¸¯"ã€"æ—¥æœ¬"

### countries - åˆ—å‡ºæ‰€æœ‰å›½å®¶

åˆ—å‡ºæ‰€æœ‰å·²é…ç½®çš„å›½å®¶/åœ°åŒºåŠå…¶ä»»åŠ¡æ•°é‡ã€‚

```bash
uv run python scheduler_cli.py countries
```

### history - æŸ¥çœ‹çˆ¬å–å†å²

æŸ¥çœ‹çˆ¬å–å†å²è®°å½•ï¼ŒåŒ…æ‹¬æˆåŠŸ/å¤±è´¥çŠ¶æ€ã€æ–‡ç« æ•°ã€è€—æ—¶ç­‰ã€‚

```bash
uv run python scheduler_cli.py history [--source-id SOURCE_ID] [--limit N]
```

å‚æ•°ï¼š
- `--source-id`: æŒ‡å®šæ–°é—»æºID
- `--limit`: æ˜¾ç¤ºæ•°é‡ï¼Œé»˜è®¤20

### stats - ç»Ÿè®¡ä¿¡æ¯

æŸ¥çœ‹è°ƒåº¦å™¨çš„ç»Ÿè®¡ä¿¡æ¯ã€‚

```bash
uv run python scheduler_cli.py stats
```

è¾“å‡ºä¿¡æ¯ï¼š
- æ€»ä»»åŠ¡æ•°
- å¯ç”¨/ç¦ç”¨ä»»åŠ¡æ•°
- å›½å®¶/åœ°åŒºæ•°
- æœ€è¿‘æˆåŠŸ/å¤±è´¥æ¬¡æ•°

### enable/disable - å¯ç”¨/ç¦ç”¨ä»»åŠ¡

å¯ç”¨æˆ–ç¦ç”¨æŒ‡å®šçš„çˆ¬å–ä»»åŠ¡ã€‚

```bash
uv run python scheduler_cli.py enable --source-id SOURCE_ID
uv run python scheduler_cli.py disable --source-id SOURCE_ID
```

### set-interval - è®¾ç½®ä»»åŠ¡é—´éš”

è®¾ç½®æŒ‡å®šä»»åŠ¡çš„çˆ¬å–é—´éš”æ—¶é—´ã€‚

```bash
uv run python scheduler_cli.py set-interval --source-id SOURCE_ID --interval MINUTES
```

## æ•°æ®åº“ç»“æ„

ç³»ç»Ÿä½¿ç”¨SQLiteæ•°æ®åº“ï¼ˆ`data/news_crawler.db`ï¼‰å­˜å‚¨ä»¥ä¸‹ä¿¡æ¯ï¼š

### crawl_tasks è¡¨
çˆ¬å–ä»»åŠ¡é…ç½®

| å­—æ®µ | ç±»å‹ | è¯´æ˜ |
|------|------|------|
| id | INTEGER | ä¸»é”® |
| source_id | TEXT | æ–°é—»æºIDï¼ˆå”¯ä¸€ï¼‰ |
| source_name | TEXT | æ–°é—»æºåç§° |
| url | TEXT | æ–°é—»æºURL |
| country | TEXT | å›½å®¶/åœ°åŒº |
| enabled | INTEGER | æ˜¯å¦å¯ç”¨ï¼ˆ0/1ï¼‰ |
| interval_minutes | INTEGER | çˆ¬å–é—´éš”ï¼ˆåˆ†é’Ÿï¼‰ |
| last_crawl_time | TEXT | æœ€åçˆ¬å–æ—¶é—´ |
| next_crawl_time | TEXT | ä¸‹æ¬¡çˆ¬å–æ—¶é—´ |
| created_at | TEXT | åˆ›å»ºæ—¶é—´ |
| updated_at | TEXT | æ›´æ–°æ—¶é—´ |

### crawl_history è¡¨
çˆ¬å–å†å²è®°å½•

| å­—æ®µ | ç±»å‹ | è¯´æ˜ |
|------|------|------|
| id | INTEGER | ä¸»é”® |
| task_id | INTEGER | ä»»åŠ¡IDï¼ˆå¤–é”®ï¼‰ |
| source_id | TEXT | æ–°é—»æºID |
| url | TEXT | æ–°é—»æºURL |
| status | TEXT | çŠ¶æ€ï¼ˆsuccess/failedï¼‰ |
| articles_count | INTEGER | çˆ¬å–æ–‡ç« æ•° |
| error_message | TEXT | é”™è¯¯ä¿¡æ¯ |
| crawl_time | TEXT | çˆ¬å–æ—¶é—´ |
| duration_seconds | REAL | è€—æ—¶ï¼ˆç§’ï¼‰ |

### crawl_articles è¡¨
çˆ¬å–çš„æ–‡ç« 

| å­—æ®µ | ç±»å‹ | è¯´æ˜ |
|------|------|------|
| id | INTEGER | ä¸»é”® |
| source_id | TEXT | æ–°é—»æºID |
| article_id | TEXT | æ–‡ç« å”¯ä¸€ID |
| title | TEXT | æ ‡é¢˜ |
| url | TEXT | æ–‡ç« URL |
| author | TEXT | ä½œè€… |
| publish_time | TEXT | å‘å¸ƒæ—¶é—´ |
| content | TEXT | å†…å®¹ |
| summary | TEXT | æ‘˜è¦ |
| category | TEXT | åˆ†ç±» |
| tags | TEXT | æ ‡ç­¾ï¼ˆJSONï¼‰ |
| images | TEXT | å›¾ç‰‡åˆ—è¡¨ï¼ˆJSONï¼‰ |
| videos | TEXT | è§†é¢‘åˆ—è¡¨ï¼ˆJSONï¼‰ |
| created_at | TEXT | åˆ›å»ºæ—¶é—´ |
| updated_at | TEXT | æ›´æ–°æ—¶é—´ |

## æ‰©å±•æ–°çš„æ–°é—»æº

### æ–¹æ³•1ï¼šä½¿ç”¨SimpleListCrawlerï¼ˆæ¨èï¼‰

å¯¹äºæ ‡å‡†çš„"åˆ—è¡¨é¡µ + è¯¦æƒ…é¡µ"ç»“æ„çš„æ–°é—»ç½‘ç«™ï¼Œå¯ä»¥ç›´æ¥ä½¿ç”¨`SimpleListCrawler`ï¼š

```python
from news_crawler.generic.crawler import SimpleListCrawler

def create_my_news_crawler():
    return SimpleListCrawler(
        source_id="my_news",
        source_name="æˆ‘çš„æ–°é—»ç½‘",
        base_url="https://www.mynews.com",
        list_url="https://www.mynews.com/news",
        list_selector="div.news-item",           # æ–‡ç« åˆ—è¡¨é¡¹é€‰æ‹©å™¨
        title_selector="h3.title::text",         # æ ‡é¢˜é€‰æ‹©å™¨
        link_selector="a::attr(href)",           # é“¾æ¥é€‰æ‹©å™¨
        article_title_selector="h1.headline::text",     # æ–‡ç« é¡µæ ‡é¢˜
        article_content_selector="div.content p",        # æ–‡ç« é¡µå†…å®¹
        article_time_selector="time::text",              # å‘å¸ƒæ—¶é—´
        article_author_selector="span.author::text"      # ä½œè€…
    )
```

### æ–¹æ³•2ï¼šç»§æ‰¿GenericNewsCrawler

å¯¹äºå¤æ‚çš„ç½‘ç«™ç»“æ„ï¼Œå¯ä»¥ç»§æ‰¿`GenericNewsCrawler`å¹¶å®ç°è‡ªå®šä¹‰é€»è¾‘ï¼š

```python
from news_crawler.generic.crawler import GenericNewsCrawler
from parsel import Selector

class MyNewsCrawler(GenericNewsCrawler):
    def get_article_list_selector(self) -> str:
        return "div.article-list > article"
    
    def parse_article_item(self, element: Selector):
        title = element.css("h2.title::text").get()
        url = element.css("a.link::attr(href)").get()
        return {"title": title, "url": url}
    
    def parse_article_content(self, html: str, url: str):
        # è‡ªå®šä¹‰è§£æé€»è¾‘
        selector = Selector(html)
        # ...
        return news_item
```

### æ³¨å†Œçˆ¬è™«

åœ¨`news_crawler/sites/crawlers.py`ä¸­æ³¨å†Œæ–°çˆ¬è™«ï¼š

```python
CRAWLER_FACTORIES = {
    # ... ç°æœ‰çˆ¬è™«
    'my_news': create_my_news_crawler,
}
```

### æ·»åŠ åˆ°é…ç½®æ–‡ä»¶

åœ¨`news_crawler/config/news_sources.json`ä¸­æ·»åŠ æ–°é—»æºï¼š

```json
{
  "id": "my_news",
  "name": "æˆ‘çš„æ–°é—»ç½‘",
  "country": "ä¸­å›½",
  "url": "https://www.mynews.com",
  "category": "ç»¼åˆ",
  "language": "zh-CN",
  "enabled": true
}
```

## ä½¿ç”¨ç¤ºä¾‹

### ç¤ºä¾‹1ï¼šæŒ‰å›½å®¶çˆ¬å–æ–°é—»

```bash
# 1. åˆ—å‡ºå°æ¹¾çš„æ‰€æœ‰æ–°é—»æº
uv run python scheduler_cli.py list --country å°æ¹¾

# 2. æ‰‹åŠ¨æ‰§è¡Œå°æ¹¾æŸä¸ªæ–°é—»æº
uv run python scheduler_cli.py run --source-id ltn

# 3. æŸ¥çœ‹çˆ¬å–ç»“æœ
uv run python scheduler_cli.py history --source-id ltn
```

### ç¤ºä¾‹2ï¼šè®¾ç½®ä¸åŒé—´éš”

```bash
# é‡è¦æ–°é—»æºè®¾ç½®è¾ƒçŸ­é—´éš”ï¼ˆ30åˆ†é’Ÿï¼‰
uv run python scheduler_cli.py set-interval --source-id cnn --interval 30
uv run python scheduler_cli.py set-interval --source-id bbc --interval 30

# ä¸€èˆ¬æ–°é—»æºè®¾ç½®æ­£å¸¸é—´éš”ï¼ˆ60åˆ†é’Ÿï¼‰
uv run python scheduler_cli.py set-interval --source-id zaobao --interval 60

# ä¸å¤ªé‡è¦çš„æºè®¾ç½®è¾ƒé•¿é—´éš”ï¼ˆ180åˆ†é’Ÿï¼‰
uv run python scheduler_cli.py set-interval --source-id some_news --interval 180
```

### ç¤ºä¾‹3ï¼šç›‘æ§çˆ¬å–çŠ¶æ€

```bash
# å¯åŠ¨è°ƒåº¦å™¨
uv run python scheduler_cli.py start

# åœ¨å¦ä¸€ä¸ªç»ˆç«¯ç›‘æ§
watch -n 10 "uv run python scheduler_cli.py stats"
watch -n 30 "uv run python scheduler_cli.py history --limit 10"
```

## æ³¨æ„äº‹é¡¹

1. **éµå®ˆrobots.txt** - è¯·éµå®ˆç›®æ ‡ç½‘ç«™çš„çˆ¬è™«åè®®
2. **æ§åˆ¶é¢‘ç‡** - å»ºè®®è®¾ç½®åˆç†çš„çˆ¬å–é—´éš”ï¼Œé¿å…å¯¹ç›®æ ‡æœåŠ¡å™¨é€ æˆå‹åŠ›
3. **å¼‚å¸¸å¤„ç†** - ç³»ç»Ÿä¼šè‡ªåŠ¨è®°å½•å¤±è´¥çš„ä»»åŠ¡ï¼Œå¯é€šè¿‡historyå‘½ä»¤æŸ¥çœ‹
4. **æ•°æ®å»é‡** - ç³»ç»Ÿä¼šè‡ªåŠ¨æ£€æµ‹å¹¶è·³è¿‡å·²çˆ¬å–çš„æ–‡ç« ï¼ˆåŸºäºsource_id + article_idï¼‰
5. **ä»…ä¾›å­¦ä¹ ** - æœ¬é¡¹ç›®ä»…ä¾›å­¦ä¹ å’Œç ”ç©¶ä½¿ç”¨ï¼Œä¸å¾—ç”¨äºå•†ä¸šç”¨é€”

## æŠ€æœ¯æ ˆ

- **Python 3.8+**
- **SQLite 3** - æ•°æ®å­˜å‚¨
- **curl_cffi** - HTTPè¯·æ±‚
- **parsel** - HTMLè§£æ
- **tenacity** - é‡è¯•æœºåˆ¶
- **threading** - å¤šçº¿ç¨‹è°ƒåº¦

## æœªæ¥è®¡åˆ’

- [ ] Web UIç®¡ç†ç•Œé¢
- [ ] æ›´å¤šæ–°é—»æºæ”¯æŒ
- [ ] RSSè®¢é˜…æ”¯æŒ
- [ ] æ–‡ç« å»é‡ç®—æ³•ä¼˜åŒ–
- [ ] åˆ†å¸ƒå¼çˆ¬å–æ”¯æŒ
- [ ] æ•°æ®å¯¼å‡ºåŠŸèƒ½ï¼ˆCSVã€Excelï¼‰
- [ ] å®æ—¶æ¨é€é€šçŸ¥
- [ ] AIå†…å®¹æ‘˜è¦

## è®¸å¯è¯

æœ¬é¡¹ç›®ä»…ä¾›å­¦ä¹ å’Œç ”ç©¶ä½¿ç”¨ã€‚ä½¿ç”¨æœ¬é¡¹ç›®å³è¡¨ç¤ºæ‚¨åŒæ„ï¼š
- ä¸å°†å…¶ç”¨äºå•†ä¸šç›®çš„
- ä¸è¿›è¡Œå¤§è§„æ¨¡çˆ¬å–
- éµå®ˆç›¸å…³æ³•å¾‹æ³•è§„å’Œç›®æ ‡ç½‘ç«™çš„ä½¿ç”¨æ¡æ¬¾

## è´¡çŒ®

æ¬¢è¿æäº¤Issueå’ŒPull Requestï¼

ç‰¹åˆ«æ¬¢è¿è´¡çŒ®ï¼š
- æ–°çš„æ–°é—»æºæ”¯æŒ
- çˆ¬è™«ç®—æ³•ä¼˜åŒ–
- Bugä¿®å¤
- æ–‡æ¡£æ”¹è¿›
