# å›½é™…æ–°é—»çˆ¬è™«å¿«é€Ÿå¼€å§‹æŒ‡å—

## ğŸ“‹ æ¦‚è¿°

æœ¬é¡¹ç›®æ–°å¢äº†å›½é™…æ–°é—»çˆ¬è™«åŠŸèƒ½ï¼Œæ”¯æŒä»å…¨çƒ 130+ ä¸ªä¸»æµæ–°é—»ç½‘ç«™è‡ªåŠ¨çˆ¬å–å†…å®¹ï¼Œå¹¶æä¾›å®šæ—¶æ‰«æã€æ›´æ–°æ£€æµ‹å’Œåˆ†ç±»ç®¡ç†åŠŸèƒ½ã€‚

## ğŸŒ æ”¯æŒçš„ç½‘ç«™

### æŒ‰åœ°åŒºåˆ†ç±»

- **ä¸œäºš** (19ä¸ªç½‘ç«™): æ—¥æœ¬ã€éŸ©å›½ã€æœé²œ
- **ä¸œå—äºš** (15ä¸ªç½‘ç«™): é©¬æ¥è¥¿äºšã€æ–°åŠ å¡ã€è¶Šå—ã€ç¼…ç”¸
- **å¤§ä¸­å** (46ä¸ªç½‘ç«™): é¦™æ¸¯ã€æ¾³é—¨ã€å°æ¹¾
- **æ¬§æ´²** (19ä¸ªç½‘ç«™): è‹±å›½ã€æ³•å›½ã€å¾·å›½ã€çˆ±å°”å…°ã€ä¿„ç½—æ–¯
- **åŒ—ç¾** (22ä¸ªç½‘ç«™): ç¾å›½
- **å¤§æ´‹æ´²** (5ä¸ªç½‘ç«™): æ¾³å¤§åˆ©äºšã€æ–°è¥¿å…°
- **å—äºš** (3ä¸ªç½‘ç«™): å°åº¦
- **å…¶ä»–** (3ä¸ªç½‘ç«™): é˜¿å¡æ‹œç–†

### ä¸»è¦ç½‘ç«™

- **ç¾å›½** (22): çº½çº¦æ—¶æŠ¥ã€åå°”è¡—æ—¥æŠ¥ã€CNNã€BBCã€ç¾è”ç¤¾ã€å½­åšç¤¾ç­‰
- **æ—¥æœ¬** (14): å…±åŒç¤¾ã€NHKã€æœæ—¥æ–°é—»ã€è¯»å–æ–°é—»ã€æ—¥ç»æ–°é—»ç­‰
- **é¦™æ¸¯** (21): è‹¹æœæ—¥æŠ¥ã€å—åæ—©æŠ¥ã€é¦™æ¸¯01ã€ç«‹åœºæ–°é—»ç­‰
- **è‹±å›½** (8): è·¯é€ç¤¾ã€é‡‘èæ—¶æŠ¥ã€å«æŠ¥ã€æ³°æ™¤å£«æŠ¥ç­‰
- **å°æ¹¾** (13): è‡ªç”±æ—¶æŠ¥ã€è”åˆæŠ¥ã€ä¸­æ—¶ç”µå­æŠ¥ç­‰

å®Œæ•´åˆ—è¡¨è¯·æŸ¥çœ‹: `news_crawler/international_news/README.md`

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. å®‰è£…ä¾èµ–

```bash
# ç¡®ä¿å·²å®‰è£…åŸºç¡€ä¾èµ–
pip3 install tenacity parsel requests

# å¯é€‰ï¼šå®‰è£… curl_cffi ä»¥è·å¾—æ›´å¥½çš„çˆ¬å–æ•ˆæœ
pip3 install curl_cffi
```

### 2. åˆå§‹åŒ–é…ç½®

```bash
# åˆå§‹åŒ–æ•°æ®åº“å’Œç½‘ç«™é…ç½®
python3 -c "from news_crawler.international_news import ConfigManager; ConfigManager().load_site_configs()"
```

### 3. åŸºæœ¬ä½¿ç”¨

```bash
# æŸ¥çœ‹æ‰€æœ‰æ”¯æŒçš„å›½å®¶
python3 -m news_crawler.international_news.cli list --countries

# æŸ¥çœ‹æŸä¸ªå›½å®¶çš„æ‰€æœ‰ç½‘ç«™
python3 -m news_crawler.international_news.cli list --country ç¾å›½

# æ‰«æç‰¹å®šå›½å®¶çš„æ–°é—»ï¼ˆä¸€æ¬¡æ€§ï¼‰
python3 -m news_crawler.international_news.cli scan --country æ—¥æœ¬ --max-articles 5

# æ‰«ææ•´ä¸ªåœ°åŒº
python3 -m news_crawler.international_news.cli scan --region ä¸œäºš --max-articles 3

# æŸ¥çœ‹çˆ¬å–ç»Ÿè®¡
python3 -m news_crawler.international_news.cli stats --days 7
```

### 4. å¯åŠ¨å®šæ—¶æ‰«æ

```bash
# å¯åŠ¨æŒç»­æ‰«æï¼ˆæ¯å°æ—¶æ£€æŸ¥ä¸€æ¬¡ï¼‰
python3 -m news_crawler.international_news.cli start --interval 3600

# åªæ‰«æç‰¹å®šå›½å®¶ï¼Œæ¯30åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡
python3 -m news_crawler.international_news.cli start --country ç¾å›½ --interval 1800

# åªæ‰«æç‰¹å®šåœ°åŒº
python3 -m news_crawler.international_news.cli start --region ä¸œäºš --interval 3600
```

## ğŸ“– è¯¦ç»†ä½¿ç”¨

### åˆ—å‡ºç½‘ç«™

```bash
# åˆ—å‡ºæ‰€æœ‰å›½å®¶
python3 -m news_crawler.international_news.cli list --countries

# åˆ—å‡ºæ‰€æœ‰åœ°åŒºåˆ†ç»„
python3 -m news_crawler.international_news.cli list --regions

# åˆ—å‡ºæŸä¸ªå›½å®¶çš„ç½‘ç«™
python3 -m news_crawler.international_news.cli list --country æ—¥æœ¬

# åˆ—å‡ºæŸä¸ªåœ°åŒºçš„æ‰€æœ‰ç½‘ç«™
python3 -m news_crawler.international_news.cli list --region æ¬§æ´²
```

### ä¸€æ¬¡æ€§æ‰«æ

```bash
# æ‰«ææ‰€æœ‰ç½‘ç«™
python3 -m news_crawler.international_news.cli scan --all --max-articles 5

# æ‰«æç‰¹å®šå›½å®¶
python3 -m news_crawler.international_news.cli scan --country ç¾å›½ --max-articles 10

# æ‰«æç‰¹å®šåœ°åŒº
python3 -m news_crawler.international_news.cli scan --region ä¸œäºš --max-articles 5

# æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯å’Œæ–‡ç« åˆ—è¡¨
python3 -m news_crawler.international_news.cli scan --country æ—¥æœ¬ --verbose --show-articles

# è‡ªå®šä¹‰å¹¶å‘çº¿ç¨‹æ•°
python3 -m news_crawler.international_news.cli scan --all --workers 10 --max-articles 5
```

### æŒç»­å®šæ—¶æ‰«æ

```bash
# é»˜è®¤æ¯å°æ—¶æ‰«æä¸€æ¬¡
python3 -m news_crawler.international_news.cli start --interval 3600

# æ¯30åˆ†é’Ÿæ‰«æä¸€æ¬¡ç‰¹å®šå›½å®¶
python3 -m news_crawler.international_news.cli start --country æ—¥æœ¬ --interval 1800

# æ¯2å°æ—¶æ‰«æä¸€æ¬¡ç‰¹å®šåœ°åŒº
python3 -m news_crawler.international_news.cli start --region ä¸œäºš --interval 7200 --max-articles 10
```

### æŸ¥çœ‹ç»Ÿè®¡ä¿¡æ¯

```bash
# æŸ¥çœ‹æœ€è¿‘7å¤©çš„ç»Ÿè®¡
python3 -m news_crawler.international_news.cli stats --days 7

# æŸ¥çœ‹ç»Ÿè®¡å¹¶æ˜¾ç¤ºæœ€è¿‘çš„çˆ¬å–å†å²
python3 -m news_crawler.international_news.cli stats --days 30 --history --limit 50
```

### é…ç½®ç½‘ç«™

```bash
# åˆ—å‡ºæ‰€æœ‰å¯é…ç½®çš„ç½‘ç«™
python3 -m news_crawler.international_news.cli config --list-sites

# å¯ç”¨æŸä¸ªç½‘ç«™
python3 -m news_crawler.international_news.cli config --site "BBC" --enable

# ç¦ç”¨æŸä¸ªç½‘ç«™
python3 -m news_crawler.international_news.cli config --site "CNN" --disable

# è®¾ç½®æ‰«æé—´éš”ï¼ˆç§’ï¼‰
python3 -m news_crawler.international_news.cli config --site "çº½çº¦æ—¶æŠ¥" --interval 7200

# åŒæ—¶è®¾ç½®å¤šä¸ªå‚æ•°
python3 -m news_crawler.international_news.cli config --site "æ—¥ç»æ–°é—»" --enable --interval 3600
```

## ğŸ”§ Python API ä½¿ç”¨

### åŸºæœ¬çˆ¬å–ç¤ºä¾‹

```python
from news_crawler.international_news import InternationalNewsCrawler

# åˆ›å»ºçˆ¬è™«å®ä¾‹
crawler = InternationalNewsCrawler(
    news_url="https://www.bbc.com/news/world",
    site_config={
        'name': 'BBC',
        'type': 'broadcast',
        'encoding': 'utf-8'
    }
)

# æå–æœ€æ–°æ–‡ç« åˆ—è¡¨
articles = crawler.extract_latest_articles(max_articles=10)
for article in articles:
    print(f"æ ‡é¢˜: {article['title']}")
    print(f"URL: {article['url']}\n")

# çˆ¬å–å•ç¯‡æ–‡ç« 
crawler_single = InternationalNewsCrawler(
    news_url="https://www.bbc.com/news/world-12345678",
    site_config={'name': 'BBC'}
)
news_item = crawler_single.run()
print(f"æ ‡é¢˜: {news_item.title}")
print(f"ä½œè€…: {news_item.meta_info.author_name}")
print(f"å†…å®¹: {len(news_item.contents)} ä¸ªå†…å®¹é¡¹")
```

### ä½¿ç”¨é…ç½®ç®¡ç†å™¨

```python
from news_crawler.international_news import ConfigManager

# åˆå§‹åŒ–ç®¡ç†å™¨
manager = ConfigManager()
manager.load_site_configs()

# è·å–æ‰€æœ‰ç¾å›½ç½‘ç«™
us_sites = manager.get_sites_by_filter(country="ç¾å›½")
print(f"ç¾å›½æœ‰ {len(us_sites)} ä¸ªæ–°é—»ç½‘ç«™")

# è·å–éœ€è¦æ‰«æçš„ç½‘ç«™ï¼ˆæ ¹æ®æ‰«æé—´éš”ï¼‰
sites_to_scan = manager.get_sites_to_scan()
print(f"å½“å‰éœ€è¦æ‰«æ {len(sites_to_scan)} ä¸ªç½‘ç«™")

# æŸ¥çœ‹ç»Ÿè®¡ä¿¡æ¯
stats = manager.get_crawl_statistics(days=7)
print(f"7å¤©å†…çˆ¬å–æ¬¡æ•°: {stats['total_crawls']}")
print(f"æˆåŠŸç‡: {stats['success_rate']}")
print(f"çˆ¬å–æ–‡ç« æ€»æ•°: {stats['total_articles']}")
```

### ä½¿ç”¨è°ƒåº¦å™¨è¿›è¡Œæ‰¹é‡æ‰«æ

```python
from news_crawler.international_news import NewsScheduler, ConfigManager

# åˆå§‹åŒ–
manager = ConfigManager()
manager.load_site_configs()

scheduler = NewsScheduler(
    config_manager=manager,
    max_workers=5  # å¹¶å‘çº¿ç¨‹æ•°
)

# ä¸€æ¬¡æ€§æ‰«ææ‰€æœ‰ç½‘ç«™
results = scheduler.scan_all_sites(max_articles_per_site=10)
print(f"æ‰«æäº† {len(results)} ä¸ªç½‘ç«™")
print(f"å‘ç° {sum(r['new_articles'] for r in results)} ç¯‡æ–°æ–‡ç« ")

# åªæ‰«æç‰¹å®šå›½å®¶
results = scheduler.scan_all_sites(
    country="æ—¥æœ¬",
    max_articles_per_site=5,
    parallel=True
)

# å¯åŠ¨æŒç»­æ‰«æï¼ˆé˜»å¡ï¼‰
scheduler.start_continuous_scanning(
    check_interval=3600,  # æ¯å°æ—¶æ£€æŸ¥ä¸€æ¬¡
    max_articles_per_site=10
)
```

### è‡ªå®šä¹‰å›è°ƒå‡½æ•°

```python
from news_crawler.international_news import NewsScheduler, ConfigManager

def on_article_crawled(news_item, site_name, country):
    """å½“æ–‡ç« è¢«çˆ¬å–æ—¶è§¦å‘"""
    print(f"[{country}] {site_name}: {news_item.title}")
    # åœ¨è¿™é‡Œæ·»åŠ è‡ªå®šä¹‰å¤„ç†é€»è¾‘
    # ä¾‹å¦‚ï¼šå‘é€é€šçŸ¥ã€å­˜å…¥æ•°æ®åº“ã€è§¦å‘åˆ†æç­‰

manager = ConfigManager()
manager.load_site_configs()

scheduler = NewsScheduler(
    config_manager=manager,
    on_article_crawled=on_article_crawled
)

# æ‰«ææ—¶ä¼šè§¦å‘å›è°ƒ
results = scheduler.scan_all_sites(max_articles_per_site=5)
```

## ğŸ“Š æ•°æ®å­˜å‚¨

### æ–‡ä»¶å­˜å‚¨

çˆ¬å–çš„æ–°é—»å†…å®¹ä¿å­˜åœ¨ `data/international_news/` ç›®å½•ä¸‹ï¼Œæ¯ç¯‡æ–‡ç« ä¸€ä¸ª JSON æ–‡ä»¶ï¼š

```json
{
  "title": "æ–‡ç« æ ‡é¢˜",
  "news_url": "https://example.com/article",
  "news_id": "unique_id",
  "meta_info": {
    "author_name": "ä½œè€…å",
    "publish_time": "2024-01-01 12:00:00"
  },
  "contents": [
    {"type": "text", "content": "æ®µè½å†…å®¹", "desc": ""},
    {"type": "image", "content": "å›¾ç‰‡URL", "desc": "å›¾ç‰‡æè¿°"}
  ],
  "texts": ["æ®µè½1", "æ®µè½2"],
  "images": ["å›¾ç‰‡URL1", "å›¾ç‰‡URL2"],
  "extra": {
    "site_name": "ç½‘ç«™å",
    "site_type": "ç½‘ç«™ç±»å‹",
    "extracted_at": "2024-01-01T12:00:00"
  }
}
```

### æ•°æ®åº“å­˜å‚¨

çˆ¬å–å†å²å­˜å‚¨åœ¨ SQLite æ•°æ®åº“ `data/international_news/crawl_history.db`:

- **site_configs**: ç½‘ç«™é…ç½®ï¼ˆæ‰«æé—´éš”ã€å¯ç”¨çŠ¶æ€ç­‰ï¼‰
- **crawl_history**: çˆ¬å–å†å²è®°å½•
- **latest_articles**: æœ€æ–°æ–‡ç« è¿½è¸ªï¼ˆç”¨äºæ›´æ–°æ£€æµ‹ï¼‰

## âš™ï¸ é…ç½®è¯´æ˜

### æ‰«æé—´éš”

æ¯ä¸ªç½‘ç«™å¯ä»¥é…ç½®ç‹¬ç«‹çš„æ‰«æé—´éš”ï¼ˆç§’ï¼‰ï¼š

- é»˜è®¤: 3600 ç§’ï¼ˆ1å°æ—¶ï¼‰
- å»ºè®®èŒƒå›´: 1800-7200 ç§’ï¼ˆ30åˆ†é’Ÿ - 2å°æ—¶ï¼‰
- é‡è¦ç½‘ç«™å¯è®¾ç½®è¾ƒçŸ­é—´éš”
- ä¸å¸¸æ›´æ–°çš„ç½‘ç«™å¯è®¾ç½®è¾ƒé•¿é—´éš”

### å¹¶å‘è®¾ç½®

- `max_workers`: å¹¶å‘çº¿ç¨‹æ•°ï¼Œé»˜è®¤ 5
- å»ºè®®æ ¹æ®ç½‘ç»œå¸¦å®½è°ƒæ•´
- é¿å…è®¾ç½®è¿‡é«˜ä»¥å…è¢«ç½‘ç«™å°ç¦

### æ–‡ç« æ•°é‡é™åˆ¶

- `max_articles_per_site`: æ¯ä¸ªç½‘ç«™çˆ¬å–çš„æœ€å¤§æ–‡ç« æ•°
- é»˜è®¤: 10 ç¯‡
- å»ºè®®: 5-20 ç¯‡
- é¦–æ¬¡è¿è¡Œå¯è®¾ç½®è¾ƒå¤§å€¼

## ğŸ¯ ä½¿ç”¨åœºæ™¯

### åœºæ™¯1: ç›‘æ§ç‰¹å®šå›½å®¶çš„æ–°é—»

```bash
# æ¯30åˆ†é’Ÿæ‰«æç¾å›½ä¸»æµåª’ä½“
python3 -m news_crawler.international_news.cli start \
    --country ç¾å›½ \
    --interval 1800 \
    --max-articles 5
```

### åœºæ™¯2: ç›‘æ§æ•´ä¸ªåœ°åŒºçš„æ–°é—»

```bash
# æ¯å°æ—¶æ‰«æä¸œäºšåœ°åŒºï¼ˆæ—¥æœ¬ã€éŸ©å›½ã€æœé²œï¼‰
python3 -m news_crawler.international_news.cli start \
    --region ä¸œäºš \
    --interval 3600 \
    --max-articles 10
```

### åœºæ™¯3: å…¨çƒæ–°é—»ç›‘æ§

```bash
# æ¯2å°æ—¶æ‰«ææ‰€æœ‰ç½‘ç«™
python3 -m news_crawler.international_news.cli start \
    --interval 7200 \
    --max-articles 5 \
    --workers 10
```

### åœºæ™¯4: ä¸€æ¬¡æ€§æ‰¹é‡é‡‡é›†

```bash
# ä¸€æ¬¡æ€§é‡‡é›†æ‰€æœ‰ç½‘ç«™çš„æœ€æ–°å†…å®¹
python3 -m news_crawler.international_news.cli scan \
    --all \
    --max-articles 20 \
    --workers 10 \
    --verbose
```

## ğŸ“ æ³¨æ„äº‹é¡¹

1. **éµå®ˆ robots.txt**: çˆ¬å–å‰è¯·æ£€æŸ¥ç›®æ ‡ç½‘ç«™çš„ robots.txt
2. **æ§åˆ¶é¢‘ç‡**: é¿å…è¿‡äºé¢‘ç¹çš„è¯·æ±‚ï¼Œå»ºè®®æ¯ä¸ªç½‘ç«™é—´éš”è‡³å°‘ 1-2 ç§’
3. **ç½‘ç»œç¯å¢ƒ**: æŸäº›ç½‘ç«™å¯èƒ½éœ€è¦ä»£ç†æ‰èƒ½è®¿é—®
4. **æ³•å¾‹åˆè§„**: ä»…ç”¨äºå­¦ä¹ ç ”ç©¶ï¼Œä¸å¾—ç”¨äºå•†ä¸šç”¨é€”
5. **ç½‘ç«™å˜åŒ–**: ç½‘ç«™ç»“æ„å¯èƒ½å˜åŒ–å¯¼è‡´çˆ¬å–å¤±è´¥ï¼Œéœ€å®šæœŸæ£€æŸ¥

## ğŸ”— ç›¸å…³æ–‡æ¡£

- å®Œæ•´æ–‡æ¡£: `news_crawler/international_news/README.md`
- é¡¹ç›®ä¸»æ–‡æ¡£: `README.md`
- Dockeréƒ¨ç½²: `DOCKER_DEPLOYMENT.md`

## â“ å¸¸è§é—®é¢˜

### Q: å¦‚ä½•æ·»åŠ æ–°ç½‘ç«™ï¼Ÿ

A: ç¼–è¾‘ `news_crawler/international_news/configs/sites_config.py`ï¼Œåœ¨å¯¹åº”å›½å®¶åˆ—è¡¨ä¸­æ·»åŠ ç½‘ç«™é…ç½®ã€‚

### Q: å¦‚ä½•ä¿®æ”¹æŸä¸ªç½‘ç«™çš„æ‰«æé—´éš”ï¼Ÿ

A: ä½¿ç”¨ config å‘½ä»¤ï¼š
```bash
python3 -m news_crawler.international_news.cli config --site "ç½‘ç«™å" --interval 7200
```

### Q: å¦‚ä½•æŸ¥çœ‹çˆ¬å–æ˜¯å¦æˆåŠŸï¼Ÿ

A: ä½¿ç”¨ stats å‘½ä»¤æŸ¥çœ‹ç»Ÿè®¡ä¿¡æ¯ï¼š
```bash
python3 -m news_crawler.international_news.cli stats --days 7 --history
```

### Q: çˆ¬å–å¤±è´¥æ€ä¹ˆåŠï¼Ÿ

A: æ£€æŸ¥ï¼š
1. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸
2. ç›®æ ‡ç½‘ç«™æ˜¯å¦å¯è®¿é—®
3. æ˜¯å¦è¢«ç½‘ç«™åçˆ¬è™«æœºåˆ¶æ‹¦æˆª
4. æŸ¥çœ‹é”™è¯¯æ—¥å¿—è·å–è¯¦ç»†ä¿¡æ¯

### Q: å¦‚ä½•åœæ­¢æŒç»­æ‰«æï¼Ÿ

A: æŒ‰ Ctrl+C åœæ­¢ç¨‹åº

---

**å¦‚éœ€å¸®åŠ©ï¼Œè¯·æŸ¥é˜…å®Œæ•´æ–‡æ¡£æˆ–æäº¤ Issueï¼**
